+++
date = "2019-11-20T19:29:37-07:00"
draft= false
title= '"高大上"的数据工程师'
categories= ["杂技浅尝"]
toc= true
+++

国外很多知名互联网公司现在都有 Data Scientist 的职位，翻译过来非常吓人，叫数据科学家，读着高端大气，看着能上天。
而且很多时候的甚至要求学历是计算机博士。


作为金字塔顶端之一的程序员职位，大家或多或少都有一些憧憬，今天也看到了一篇文章的介绍，这里也记录一下，偶尔回来瞻仰瞻仰。

如果想成为一个优秀的数据工程师，需要掌握统计学和线性代数的相关知识，必须有熟练的编程技巧和数据抽象的能力，还要能做数据的可视化。完成了数据平台的构建，还有机器学习等着，还有人工智能以及不可知的未来等着。

有时候一想到这些，甚至会产生特别绝望的想法：人类终究还是要输给数据吧。

即使是最基础的数据处理链路，比如数据清洗、存储、分析和计算，也会碰到各种问题。一个大牛讲过他做的一个用户行为分析的数据平台，链路是这样的：`数据上报，通过 hash 名称存成 gz 文件，然后用 Python 进行数据清洗，存入 Hadoop 集群的 HDFS，再进行离线计算，通过 Spark SQL 把部分数据存入 MySQL，并提供 HTTP API，给前端做展示。`

优化后的策略是：`对 App 埋点数据格式进行重新整理和规划，引入 Presto，通过 ETL 程序把 HDFS 文件数据导入 Hive，并做 ORC 压缩处理，形成二进制格式（速度快，节省空间 70%），并进行分区。然后通过 Presto jdbc 定时调度任务，将 Hive 数据做统计聚合至 MySQL。优化后的离线分析速度和灵活性都大大增加了。`

推荐一下 Presto，这是一个非常优秀的分布式 SQL 查询引擎，可以实现全内存并行计算，动态编译执行计划，进行本地化计算。既适用交互式分析查询，也可以通过 API 实现数据聚合，数据量可以支持 GB 到 PB，非常惊人。

即使是一套成熟的技术方案，当去处理自己的实际业务时，也会遇到各种问题。需要熟练掌握这些技术和引擎的同时，熟知你的业务数据，才能抽丝剥茧，层层推进，抵达彼岸。

